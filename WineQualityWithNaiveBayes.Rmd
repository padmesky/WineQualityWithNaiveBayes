---
title: "Predicting Wine Quality with Naive Bayes Algorithm"
subtitle: "Naive Bayes Algorithm"
date: "`r format(Sys.time(), '%d %B %Y')`"
author: "Havva Nur Elveren"
output:
  html_document:
      theme: journal
      toc: yes
      toc_depth: 4
      #toc_float: true
  word_document:
      toc: yes
      toc_depth: 4
      #toc_float: true
  pdf_document:
      toc: yes
      theme: journal
      toc_depth: 4
      #toc_float: true
---
---
# Objective: Predicting Wine Quality
Can we predict wine quality based on its features such as acidity, alcohol, sugar or sulfate level? In this project, we'll predict Wine Quality with looking at the value of different features of a wine. We'll use a data set that has been collected from red wine variants of the Portuguese "Vinho Verde" wine. If quality is greater than 6.5 it is considered as good wine, otherwise it is considered as bad wine.

# Data Description:
* 1.6K Row with 12 Column. You can download the data from the link https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009
```{r}
library(kableExtra)

dt <- data.frame(Name = c("fixed.acidity", "volatile.acidity", "citric.acid", "residual.sugar", "chlorides", "free.sulfur.dioxide", "total.sulfur.dioxide",
"density", "pH", "sulphates", "alcohol", "quality"),
Description = c("most acids involved with wine or fixed or nonvolatile (do not evaporate readily)", "the amount of acetic acid in wine, which at too high of levels can lead to an unpleasant, vinegar taste", "found in small quantities, citric acid can add 'freshness' and flavor to wines", "the amount of sugar remaining after fermentation stops, it's rare to find wines with less than 1 gram/liter and wines with greater than", "the amount of salt in the wine", "the free form of SO2 exists in equilibrium between molecular SO2 (as a dissolved gas) and bisulfite ion; it prevents", "amount of free and bound forms of S02; in low concentrations, SO2 is mostly undetectable in wine, but at free SO2", "the density of water is close to that of water depending on the percent alcohol and sugar content", "describes how acidic or basic a wine is on a scale from 0 (very acidic) to 14 (very basic); most wines are between 3-4 on the", "a wine additive which can contribute to sulfur dioxide gas (S02) levels, wich acts as an antimicrobial and", "the percent alcohol content of the wine","Score between 0 and 10, if quality > 6.5 it's Good, otherwise it is Bad "))

dt %>%
  kbl() %>%
  kable_styling()

```

## Step 1: Load the Libraries
```{r message=FALSE, warning=FALSE}
library(ISLR)
library(caret)
library(readxl)
library(pROC)
library(lattice)
library(ggplot2)
library(dplyr)
library(e1071) 
library(corrplot)
library(kknn)
library(ggplot2)
library(multiROC)
library(MLeval)
library(AppliedPredictiveModeling)
library(corrplot)
library(Hmisc)
library(dplyr)
library(quantmod) 

```
## Step 2: Load the Data Set
```{r message=FALSE, warning=FALSE}
winedata <- read.csv("winequality-red.csv")
winedata <- data.frame(winedata, stringsAsFactors = FALSE, colnames<- TRUE )

str(winedata)
summary(winedata)

# If quality score is greater than 6.5 set quality as Good, otherwise set as Bad
winedata$quality[winedata$quality>6.5] <- 'Good'
winedata$quality[winedata$quality<= 6.5] <- 'Bad'
winedata$quality <- as.factor(winedata$quality)
table(winedata$quality)

```

## Step 3: Prepare the Test and Training Data
```{r message=FALSE, warning=FALSE}
# Use the %75 of the data for training and the rest for testing the model
trainingIndex <- createDataPartition(y = winedata$quality, p = .75, list = FALSE)
winedata_train <- winedata[trainingIndex,]
winedata_test <- winedata[-trainingIndex,]

# with excluding the quality column, scale the data with z-score
trainX <- winedata_train[,names(winedata_train) != "quality"]
preProcValues <- preProcess(x = trainX,method = c("center", "scale"))
preProcValues

```

## Step 4: Train the Model with Naive Bayes Algorithm
```{r message=FALSE, warning=FALSE}
# Train the model with navive bayes algorithm using naiveBayes function of e1071 packge
model <- naiveBayes(winedata_train, winedata_train$quality, laplace = 0)
model

prediction <- predict(model, winedata_test, type="class")
confusionMatrix(prediction, winedata_test$quality)

pMatrix <- table(prediction, winedata_test$quality)
plot(pMatrix, type = "h", main= "model prediction", col= c("blue", "red"))

```

## Step 5: Improve the Model Performance
```{r message=FALSE, warning=FALSE}
# Improve the model performance with increasing the laplace value to 1
model <- naiveBayes(winedata_train, winedata_train$quality, laplace = 1)
model

prediction <- predict(model, winedata_test, type="class")
confusionMatrix(prediction, winedata_test$quality)

pMatrix <- table(prediction, winedata_test$quality)
plot(pMatrix, type = "h", main= "model prediction", col= c("blue", "red"))

```

# Conculusion

In this project we predict wine quality with using Naive Bayes algorithm. In our
data set each wine data has a qualith value which is a score between 0-10. If 
the quality score is greater than 6.5 than the wine is considered as good wine,
otherwise it's considered as bad wine. 

Before training our model, we create the class factor with converting quality
scores to a 2 level factor which is Good and Bad. After that we partition our 
data into test and training data and start training our model.

To train our model we use naviveBayes implementation of the e1071 package. 
In our first model we set the laplace value as 0, and in our second model we 
increase the laplace value to improve the model performance by mitigating the 
errors resulted by similarities in the data. 

Both model gives almost perfect results predicting wine quality. Both model
predicts the wine quality with more than %99 accuracy, even though our data
set is not balanced and has more bad wine data than good wines. 

Given the results of our training models, we can see that Naive Bayes is highly
successful predicting wine quality on our data set. 
